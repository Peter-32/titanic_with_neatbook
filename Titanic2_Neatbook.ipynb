{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic2 Neatbook\n",
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "                                  Name   Sex  Ticket    Cabin Embarked\n",
      "count                              891   891     891      204      889\n",
      "unique                             891     2     681      147        3\n",
      "top     O'Sullivan, Miss. Bridget Mary  male  347082  B96 B98        S\n",
      "freq                                 1   577       7        4      644\n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get data here\n",
    "df = pd.read_csv(\"train.csv\") ## Edit: Your dataset\n",
    "print(df.describe(include = [np.number]))\n",
    "print(df.describe(include = ['O']))\n",
    "print(df.dtypes)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX\n",
      "\n",
      "     PassengerId  Pclass                          Name     Sex   Age  SibSp  \\\n",
      "877          878       3          Petroff, Mr. Nedelio    male  19.0      0   \n",
      "667          668       3    Rommetvedt, Mr. Knud Paust    male   NaN      0   \n",
      "349          350       3              Dimic, Mr. Jovan    male  42.0      0   \n",
      "353          354       3     Arnold-Franchi, Mr. Josef    male  25.0      1   \n",
      "172          173       3  Johnson, Miss. Eleanor Ileen  female   1.0      1   \n",
      "\n",
      "     Parch  Ticket     Fare Cabin Embarked  \n",
      "877      0  349212   7.8958   NaN        S  \n",
      "667      0  312993   7.7750   NaN        S  \n",
      "349      0  315088   8.6625   NaN        S  \n",
      "353      0  349237  17.8000   NaN        S  \n",
      "172      1  347742  11.1333   NaN        S  \n",
      "\n",
      "trainY\n",
      "\n",
      "877    0\n",
      "667    0\n",
      "349    0\n",
      "353    0\n",
      "172    1\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(df.drop(['Survived'], axis=1), ## Edit: Replace class with the Y column name\n",
    "                                                    df['Survived'], train_size=0.75, test_size=0.25) ## Edit: Same\n",
    "\n",
    "indexColumns = ['PassengerId'] ## Edit: Optionally add column names\n",
    "skipColumns = [] ## Edit: Optionally add column names\n",
    "\n",
    "print(\"trainX\\n\")\n",
    "print(trainX.head())\n",
    "print(\"\\ntrainY\\n\")\n",
    "print(trainY.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning done\n"
     ]
    }
   ],
   "source": [
    "from neatbook.neat import *\n",
    "\n",
    "# Clean training set\n",
    "neat =  Neat(trainX, trainY, indexColumns, skipColumns)\n",
    "cleanTrainX = neat.df\n",
    "cleanTrainY = neat.trainY\n",
    "\n",
    "# Clean test set\n",
    "neat.cleanNewData(testX)\n",
    "cleanTestX = neat.df\n",
    "cleanTestY = neat.getYAsNumber(testY)\n",
    "\n",
    "print(\"Cleaning done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           pclass         age       sibsp  parch        fare  name___Other  \\\n",
      "count  668.000000  668.000000  668.000000  668.0  668.000000         668.0   \n",
      "mean     2.293413   29.300898    0.390719    0.0   21.188747           1.0   \n",
      "std      0.841655    9.769036    0.627962    0.0   14.771552           0.0   \n",
      "min      1.000000   13.500000    0.000000    0.0    1.350000           1.0   \n",
      "25%      1.750000   23.000000    0.000000    0.0    7.925000           1.0   \n",
      "50%      3.000000   28.500000    0.000000    0.0   14.500000           1.0   \n",
      "75%      3.000000   35.000000    1.000000    0.0   30.500000           1.0   \n",
      "max      3.000000   47.500000    2.000000    0.0   46.500000           1.0   \n",
      "\n",
      "       sex__female   sex__male  ticket___Other  cabin___Other  embarked__C  \\\n",
      "count   668.000000  668.000000           668.0          668.0   668.000000   \n",
      "mean      0.366766    0.633234             1.0            1.0     0.197605   \n",
      "std       0.482283    0.482283             0.0            0.0     0.398491   \n",
      "min       0.000000    0.000000             1.0            1.0     0.000000   \n",
      "25%       0.000000    0.000000             1.0            1.0     0.000000   \n",
      "50%       0.000000    1.000000             1.0            1.0     0.000000   \n",
      "75%       1.000000    1.000000             1.0            1.0     0.000000   \n",
      "max       1.000000    1.000000             1.0            1.0     1.000000   \n",
      "\n",
      "       embarked__Q  embarked__S  embarked___Other  \n",
      "count   668.000000   668.000000        668.000000  \n",
      "mean      0.089820     0.709581          0.002994  \n",
      "std       0.286138     0.454296          0.054677  \n",
      "min       0.000000     0.000000          0.000000  \n",
      "25%       0.000000     0.000000          0.000000  \n",
      "50%       0.000000     1.000000          0.000000  \n",
      "75%       0.000000     1.000000          0.000000  \n",
      "max       1.000000     1.000000          1.000000  \n",
      "                 pclass   age  sibsp  parch     fare  name___Other  \\\n",
      "passengerid _id                                                      \n",
      "878         1         3  19.0      0      0   7.8958             1   \n",
      "668         2         3  28.5      0      0   7.7750             1   \n",
      "350         3         3  42.0      0      0   8.6625             1   \n",
      "354         4         3  25.0      1      0  17.8000             1   \n",
      "173         5         3  13.5      1      0  11.1333             1   \n",
      "\n",
      "                 sex__female  sex__male  ticket___Other  cabin___Other  \\\n",
      "passengerid _id                                                          \n",
      "878         1              0          1               1              1   \n",
      "668         2              0          1               1              1   \n",
      "350         3              0          1               1              1   \n",
      "354         4              0          1               1              1   \n",
      "173         5              1          0               1              1   \n",
      "\n",
      "                 embarked__C  embarked__Q  embarked__S  embarked___Other  \n",
      "passengerid _id                                                           \n",
      "878         1              0            0            1                 0  \n",
      "668         2              0            0            1                 0  \n",
      "350         3              0            0            1                 0  \n",
      "354         4              0            0            1                 0  \n",
      "173         5              0            0            1                 0  \n",
      "[0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 0 1\n",
      " 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0\n",
      " 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 0 0 1 1\n",
      " 1 0 1 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1\n",
      " 0 1 0 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0\n",
      " 1 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 0 1 1 1 0 1\n",
      " 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0\n",
      " 1 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 1 1 0 1\n",
      " 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 1 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 1 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1\n",
      " 0 1]\n",
      "           pclass         age       sibsp  parch        fare  name___Other  \\\n",
      "count  223.000000  223.000000  223.000000  223.0  223.000000         223.0   \n",
      "mean     2.354260   29.253363    0.430493    0.0   20.879352           1.0   \n",
      "std      0.819287   10.303488    0.666687    0.0   15.603083           0.0   \n",
      "min      1.000000   13.500000    0.000000    0.0    1.350000           1.0   \n",
      "25%      2.000000   21.000000    0.000000    0.0    7.895800           1.0   \n",
      "50%      3.000000   28.500000    0.000000    0.0   13.000000           1.0   \n",
      "75%      3.000000   36.000000    1.000000    0.0   34.687500           1.0   \n",
      "max      3.000000   47.500000    2.000000    0.0   46.500000           1.0   \n",
      "\n",
      "       sex__female   sex__male  ticket___Other  cabin___Other  embarked__C  \\\n",
      "count   223.000000  223.000000           223.0          223.0   223.000000   \n",
      "mean      0.309417    0.690583             1.0            1.0     0.161435   \n",
      "std       0.463293    0.463293             0.0            0.0     0.368759   \n",
      "min       0.000000    0.000000             1.0            1.0     0.000000   \n",
      "25%       0.000000    0.000000             1.0            1.0     0.000000   \n",
      "50%       0.000000    1.000000             1.0            1.0     0.000000   \n",
      "75%       1.000000    1.000000             1.0            1.0     0.000000   \n",
      "max       1.000000    1.000000             1.0            1.0     1.000000   \n",
      "\n",
      "       embarked__Q  embarked__S  embarked___Other  \n",
      "count   223.000000   223.000000             223.0  \n",
      "mean      0.076233     0.762332               0.0  \n",
      "std       0.265968     0.426612               0.0  \n",
      "min       0.000000     0.000000               0.0  \n",
      "25%       0.000000     1.000000               0.0  \n",
      "50%       0.000000     1.000000               0.0  \n",
      "75%       0.000000     1.000000               0.0  \n",
      "max       1.000000     1.000000               0.0  \n",
      "                 pclass   age  sibsp  parch     fare  name___Other  \\\n",
      "passengerid _id                                                      \n",
      "89          1         1  23.0      2      0  46.5000             1   \n",
      "203         2         3  34.0      0      0   6.4958             1   \n",
      "206         3         3  13.5      0      0  10.4625             1   \n",
      "463         4         1  47.0      0      0  38.5000             1   \n",
      "188         5         1  45.0      0      0  26.5500             1   \n",
      "\n",
      "                 sex__female  sex__male  ticket___Other  cabin___Other  \\\n",
      "passengerid _id                                                          \n",
      "89          1              1          0               1              1   \n",
      "203         2              0          1               1              1   \n",
      "206         3              1          0               1              1   \n",
      "463         4              0          1               1              1   \n",
      "188         5              0          1               1              1   \n",
      "\n",
      "                 embarked__C  embarked__Q  embarked__S  embarked___Other  \n",
      "passengerid _id                                                           \n",
      "89          1              0            0            1               0.0  \n",
      "203         2              0            0            1               0.0  \n",
      "206         3              0            0            1               0.0  \n",
      "463         4              0            0            1               0.0  \n",
      "188         5              0            0            1               0.0  \n",
      "[1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1\n",
      " 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0\n",
      " 1 0 0 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 1\n",
      " 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(cleanTrainX.describe(include = [np.number]))\n",
    "print(cleanTrainX.head())\n",
    "\n",
    "print(cleanTrainY)\n",
    "\n",
    "\n",
    "print(cleanTestX.describe(include = [np.number]))\n",
    "print(cleanTestX.head())\n",
    "\n",
    "\n",
    "print(cleanTestY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 0.9.1 of tpot is outdated. Version 0.9.2 was released 4 days ago.\n",
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 200/200 [01:35<00:00,  2.56pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8203119739647626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 300/300 [02:40<00:00,  1.49pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.8203119739647626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 400/400 [04:03<00:00,  1.05pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.8292896420154865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 500/500 [05:29<00:00,  1.44s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.8292896420154865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 600/600 [07:07<00:00,  1.41pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 0.8292896420154865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 700/700 [08:59<00:00,  1.11pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 6 - Current best internal CV score: 0.8292896420154865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 800/800 [10:40<00:00,  1.18s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 7 - Current best internal CV score: 0.8292896420154865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 900/900 [13:07<00:00,  1.14s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 8 - Current best internal CV score: 0.8292896420154865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 1000/1000 [15:19<00:00,  1.12s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 9 - Current best internal CV score: 0.8292896420154865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 1100/1100 [17:40<00:00,  1.78s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 10 - Current best internal CV score: 0.8308046234990462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 100%|██████████| 1200/1200 [19:29<00:00,  1.03pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 11 - Current best internal CV score: 0.8308046234990462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20.033862016666667 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: RandomForestClassifier(input_matrix, bootstrap=True, criterion=gini, max_features=0.4, min_samples_leaf=1, min_samples_split=14, n_estimators=100)\n",
      "0.838565022422\n",
      "\n",
      "\n",
      "TPOT is done.\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "tpot = TPOTClassifier(max_time_mins=20, ## Edit: Set to 480 to train for 8 hours\n",
    "                      population_size=100, max_eval_time_mins=5, verbosity=2)\n",
    "tpot.fit(cleanTrainX, cleanTrainY)\n",
    "print(tpot.score(cleanTestX, cleanTestY))\n",
    "tpot.export('tpot_pipeline.py')\n",
    "\n",
    "print(\"\\n\\nTPOT is done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this after TPOT is done\n",
    "\n",
    "Creates the Python_Training_Test.py file.  That file creates the optional Python_Test.py file.\n",
    "\n",
    "- **Python_Training_Test.py:** Train the model from TPOT.  Test it on a test set.\n",
    "- **Python_Test.py:** Used to test new data without model training.  The model is saved to disk during the Python_Training_Test.py script run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done creating your Python_Training_Test.py\n"
     ]
    }
   ],
   "source": [
    "with open('Python_Training_Test.py', 'w') as fileOut:\n",
    "    with open('tpot_pipeline.py', 'r') as fileIn:\n",
    "        for line in fileIn:\n",
    "            if line.startswith(\"import\") or line.startswith(\"from \"):\n",
    "                fileOut.write(line)\n",
    "    fileOut.write(\"\"\"from neatbook.neat import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "\n",
    "##### IF YOU HAVE 1 DATASET UNCOMMENT THIS CODE: #####\n",
    "\n",
    "# df = pd.read_csv('iris.csv') ## Edit: Your dataset\n",
    "# className = 'class' ## Edit: Replace class with the Y column name\n",
    "# trainX, testX, trainY, testY = train_test_split(df.drop([className], axis=1),\n",
    "#                                                     df[className], train_size=0.75, test_size=0.25)\n",
    "\n",
    "#######################################################\n",
    "\n",
    "##### IF YOU HAVE 2 DATASETS UNCOMMENT THIS CODE: #####\n",
    "\n",
    "# trainDf = pd.read_csv('train_iris.csv') ## Edit: Your dataset\n",
    "# testDf = pd.read_csv('test_iris.csv') ## Edit: Your dataset\n",
    "\n",
    "# className = 'class' ## Edit: Replace class with the Y column name\n",
    "# trainX = trainDf.drop([className], axis=1)\n",
    "# trainY = trainDf[className]\n",
    "# testX = testDf.drop([className], axis=1)\n",
    "# testY = testDf[className]\n",
    "\n",
    "#######################################################\n",
    "\n",
    "################### Set Variables: ####################\n",
    "\n",
    "indexColumns = [] ## Edit: Optionally add column names\n",
    "skipColumns = [] ## Edit: Optionally add column names\n",
    "\n",
    "#######################################################\n",
    "\n",
    "####################### Clean: ########################\n",
    "\n",
    "# Clean training set\n",
    "neat =  Neat(trainX, trainY, indexColumns, skipColumns)\n",
    "cleanTrainX = neat.df\n",
    "cleanTrainY = neat.trainY\n",
    "\n",
    "# Clean test set\n",
    "neat.cleanNewData(testX)\n",
    "cleanTestX = neat.df\n",
    "cleanTestY = neat.getYAsNumber(testY)\n",
    "\n",
    "#######################################################\n",
    "\n",
    "###################### Pipeline: ######################\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "showNextLines = False\n",
    "with open('Python_Training_Test.py', 'a') as fileOut:\n",
    "    with open('tpot_pipeline.py', 'r') as fileIn:\n",
    "        for line in fileIn:\n",
    "            if line.startswith(\"# Score\"):\n",
    "                showNextLines = True\n",
    "            elif showNextLines and not line.startswith(\"exported_pipeline.fit\") and not line.startswith(\"results\"):\n",
    "                fileOut.write(line)\n",
    "\n",
    "with open('Python_Training_Test.py', 'a') as fileOut:\n",
    "    fileOut.write(\"\"\"exported_pipeline.fit(trainX, trainY)\n",
    "results = exported_pipeline.predict(testX)\n",
    "\n",
    "#######################################################\n",
    "\n",
    "################## Confusion Matrix: ##################\n",
    "\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(cleanTestY, results))\n",
    "\n",
    "#######################################################\n",
    "\n",
    "############ Create Python_Test.py File: ##############\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "save_object(neat, 'neat.pkl')\n",
    "save_object(exported_pipeline, 'exported_pipeline.pkl')\n",
    "save_object(indexColumns, 'indexColumns.pkl')\n",
    "save_object(skipColumns, 'skipColumns.pkl')\n",
    "save_object(className, 'className.pkl')\n",
    "\n",
    "\n",
    "with open('Python_Test.py', 'w') as fileOut:\n",
    "    fileOut.write(\\\"\\\"\\\"\n",
    "#################### Get Dataset: #####################\n",
    "\n",
    "testDf = pd.read_csv('test_iris.csv') ## Edit: Your dataset\n",
    "testX = testDf.drop([className], axis=1)\n",
    "\n",
    "#######################################################\n",
    "\n",
    "################### Set Variables: ####################\n",
    "\n",
    "with open('neat.pkl', 'rb') as input:\n",
    "    neat = pickle.load(input)\n",
    "with open('exported_pipeline.pkl', 'rb') as input:\n",
    "    exported_pipeline = pickle.load(input)\n",
    "with open('indexColumns.pkl', 'rb') as input:\n",
    "    indexColumns = pickle.load(input)\n",
    "with open('skipColumns.pkl', 'rb') as input:\n",
    "    skipColumns = pickle.load(input)\n",
    "with open('className.pkl', 'rb') as input:\n",
    "    className = pickle.load(input)\n",
    "\n",
    "#######################################################\n",
    "\n",
    "####################### Clean: ########################\n",
    "\n",
    "neat.cleanNewData(testX)\n",
    "cleanTestX = neat.df\n",
    "\n",
    "#######################################################\n",
    "\n",
    "###################### Predict: #######################\n",
    "\n",
    "results = exported_pipeline.predict(cleanTestX)\n",
    "resultsDf = pd.DataFrame(results)\n",
    "submitDf = pd.concat([testDf, resultsDf], axis=1)\n",
    "submitDf.to_csv('./submit.csv')\n",
    "print(\"Done\")\n",
    "print(results)\n",
    "\n",
    "#######################################################\n",
    "\n",
    "#######################################################\n",
    "\\\"\\\"\\\"\n",
    "\"\"\")\n",
    "\n",
    "print(\"Done creating your Python_Training_Test.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
